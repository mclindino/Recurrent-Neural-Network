{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "34XSvWs9wQT_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time, math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "L37XwgfLEA5E",
    "outputId": "2597e9fb-fe93-4574-c8d0-85df632892f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 1298370\n",
      "ô\",u va”zK/…íF6HÀx5õú(óo‘niw@—\n",
      "è̀RV–-X’̂rc*bD jqÕ$dt~T9OQîI°h7É3)C0YfN!ÇàêJÿ%l1Um;4Aáe?üâ8GW`PÃBé&́ZELsç̃ÁgM―̧p.'Sk:Ó2ã“ìÍ 123\n"
     ]
    }
   ],
   "source": [
    "# Ler um arquivo em texto puro contendo o conteúdo a ser aprendido\n",
    "file = open('lfv_texts_plain.txt').read()\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)\n",
    "\n",
    "all_characters = ''.join(set(file))\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "print(all_characters, n_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "wewNlQiRf69N",
    "outputId": "b4b97e02-61ed-4f74-feae-5b5e6b012a90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a Andradina. O Bolota só ficou de olhos arregalados mas o resto da família jurou não dizer nada. Fora da casa, ninguém precisava saber que a Andradina estava voltando.\n",
      "A chegada da Andradina só na\n"
     ]
    }
   ],
   "source": [
    "chunk_len = 200\n",
    "\n",
    "# Gera um pedaço aleatório de texto com o tamanho especificado em chuck_len\n",
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1Wqh8sI7gO3k",
    "outputId": "eb178c48-92e8-49fe-c186-20e49d6ff242"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  6,  43,  41,  44, 101,  13])\n"
     ]
    }
   ],
   "source": [
    "# Converte string para uma lista de inteiros\n",
    "\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "      try:\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "      except:\n",
    "        print(c)\n",
    "        raise\n",
    "    return Variable(tensor)\n",
    "\n",
    "print(char_tensor('abcDEF'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5YsB69SvstI"
   },
   "outputs": [],
   "source": [
    "# Gera um 'exemplo' aleatório (um pedaço aleatório convertido para lista de inteiros)\n",
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kVAe8dOmxS5l"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        decoded_output = self.decoder(output.view(1, -1))\n",
    "        return decoded_output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GfJ5i2Cb1Orb"
   },
   "outputs": [],
   "source": [
    "# Gera um texto iniciando com \"prime_str\" de tamanho \"predict_len\" e variação definida por \"temperature\"\n",
    "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = rnn.init_hidden()\n",
    "    prime_input = char_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # prime_str é o texto inicial que o gerado irá completar\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = rnn(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = rnn(inp, hidden)\n",
    "        \n",
    "        # Usa a temperatura para amostrar a distribuição e escolher a saída probabilísticamente\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Adiciona o caracter predito à string de saída\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = char_tensor(predicted_char)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dIrgoMRw6-Pm"
   },
   "outputs": [],
   "source": [
    "# Treina sobre um exemplo (i.e. uma amostragem do texto)\n",
    "\n",
    "def train(inp, target):\n",
    "    hidden = rnn.init_hidden()\n",
    "    rnn.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    inp = inp\n",
    "    hidden = hidden\n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = rnn(inp[c], hidden)\n",
    "        loss += loss_metric(output, target[c].unsqueeze(0))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.data.item() / chunk_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 12053
    },
    "colab_type": "code",
    "id": "HmzVCPH2oxK8",
    "outputId": "8a1faea1-a4df-4b37-b7f0-9504504bbab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3m 44s (100 0%) 2.3991]\n",
      "Os procalina dadio eriste contade. verso a de de de mosum o ghaco hom nas tanhacte çara, Nãoçavente \n",
      "\n",
      "[7m 19s (200 0%) 2.3551]\n",
      "Os exas mande Vimora mulhadar mara homo, nrocer mara prata Parreta a pado que doconta, prara um shoi m \n",
      "\n",
      "[10m 52s (300 0%) 2.0358]\n",
      "Os peló Bé consos precia seve. Taixa forviz. Fivos estencias a cúriam acambraz, em comlivar cênil c \n",
      "\n",
      "[14m 25s (400 0%) 1.9768]\n",
      "Os do Beramende com o Astido soapos ainda. Destoio aquera. Ela não a gidão. O a mente e secentas, pa \n",
      "\n",
      "[17m 56s (500 1%) 1.8918]\n",
      "Os agrante e adais e diz pessor de algumpde lebal, Vegunte no o Homem semente, eu tempo de Calimo, a a \n",
      "\n",
      "[21m 26s (600 1%) 1.9929]\n",
      "Os do prate, não tamos paração é a minhaçãos e toberam o precite exitar. Í....\n",
      "― Partas ainte.  \n",
      "\n",
      "[24m 56s (700 1%) 1.9931]\n",
      "Os nunca concusas de explicous contente.\n",
      "Porto a Mortos pois coma do bontícico. Com conssssientas des \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50000\n",
    "print_every = 100\n",
    "hidden_size = 512\n",
    "n_layers = 2\n",
    "lr = 0.0005\n",
    "\n",
    "rnn = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)\n",
    "loss_metric = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    example = random_training_set()\n",
    "    loss = train(example[0],example[1])       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "        print(evaluate('Os', 100), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQgGglFw5HYH"
   },
   "outputs": [],
   "source": [
    "# Com a rede treinada, gerar um texto longo\n",
    "\n",
    "print(evaluate('O psicanalista de', 5500), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fkXB6Dn_scZW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM Text Generation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
